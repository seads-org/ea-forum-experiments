{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.dirname(sys.path[0])))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import umap\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "from src.paths import get_project_root, abs_path, datap\n",
    "\n",
    "sys.path.append(abs_path(\"TextClusterVisualization/scripts\"))\n",
    "os.makedirs(datap(), exist_ok=True)\n",
    "\n",
    "from graph_clustering import get_igraph_from_umap_graph, two_level_clustering\n",
    "from preprocessing import create_text_corp\n",
    "from keyword_extraction import get_keywords_for_hierarchy, convert_keywords_to_cluster_names\n",
    "\n",
    "# %env WANDB_NOTEBOOK_NAME=prepare_data_clean\n",
    "import wandb\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"all-mpnet-base-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvpetukhov\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20221109_103443-3hq1e2l7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/vpetukhov/ea-forum-analysis/runs/3hq1e2l7\" target=\"_blank\">ruby-flower-31</a></strong> to <a href=\"https://wandb.ai/vpetukhov/ea-forum-analysis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.login() # relies on WANDB_API_KEY env var\n",
    "run = wandb.init(\n",
    "    project=\"ea-forum-analysis\", job_type=\"processing\", dir=get_project_root(), config={'model_name': model_name}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas:\n",
    "- Timeline with key posts on a topic\n",
    "  - Add time dimension to my search engine?\n",
    "- Convert dendrogram into an actual table of content\n",
    "- Propagate post tags to users, show most active users per dendrogram branch\n",
    "- Improve coloschemes\n",
    "- Add time selection\n",
    "\n",
    "Improving visualization:\n",
    "- Try poincare embeddings\n",
    "- Try sentence transformers instead of word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact posts_encoded:all-mpnet-base-v2, 98.61MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact posts_raw:latest, 272.30MB. 3 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "Done. 0:0:0.0\n"
     ]
    }
   ],
   "source": [
    "enc_art = run.use_artifact(f\"posts_encoded:{model_name}\")\n",
    "enc_art.download()\n",
    "posts_art = run.use_artifact(\"posts_raw:latest\")\n",
    "\n",
    "posts_encoded = pd.read_csv(enc_art.file(), index_col=0)\n",
    "posts = Dataset.load_from_disk(posts_art.download()).to_pandas()\n",
    "\n",
    "run.config.update({'encoding_version': enc_art.version, 'data_version': posts_art.version})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10827, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = posts.loc[posts_encoded.index]\n",
    "posts = posts[posts.postedAt.dt.year > 2009]\n",
    "posts_encoded = posts_encoded.loc[posts.index]\n",
    "\n",
    "posts_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts['text'] = posts['title'] + \"\\n\\n\" + posts['body']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/umap/parametric_umap.py:148: UserWarning: tensorflow_probability not installed or incompatible to current                 tensorflow installation. Setting global_correlation_loss_weight to zero.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1495/1495 [==============================] - 13s 8ms/step - loss: 0.2833\n",
      "Epoch 2/10\n",
      "1495/1495 [==============================] - 12s 8ms/step - loss: 0.2224\n",
      "Epoch 3/10\n",
      "1495/1495 [==============================] - 12s 8ms/step - loss: 0.2083\n",
      "Epoch 4/10\n",
      "1495/1495 [==============================] - 12s 8ms/step - loss: 0.1996\n",
      "Epoch 5/10\n",
      "1495/1495 [==============================] - 12s 8ms/step - loss: 0.1945\n",
      "Epoch 6/10\n",
      "1495/1495 [==============================] - 11s 8ms/step - loss: 0.1919\n",
      "Epoch 7/10\n",
      "1495/1495 [==============================] - 12s 8ms/step - loss: 0.1897\n",
      "Epoch 8/10\n",
      "1495/1495 [==============================] - 12s 8ms/step - loss: 0.1884\n",
      "Epoch 9/10\n",
      "1495/1495 [==============================] - 12s 8ms/step - loss: 0.1861\n",
      "Epoch 10/10\n",
      "1495/1495 [==============================] - 12s 8ms/step - loss: 0.1856\n"
     ]
    }
   ],
   "source": [
    "from umap.parametric_umap import ParametricUMAP\n",
    "\n",
    "pumap = ParametricUMAP()\n",
    "par_embedding = pumap.fit_transform(posts_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_graph = get_igraph_from_umap_graph(pumap)\n",
    "\n",
    "clustering_info = two_level_clustering(\n",
    "    i_graph, posts_encoded.values, \n",
    "    top_level_resolution=0.0005, second_level_resolution=0.003, \n",
    "    min_size_level1=10, min_size_level2=10\n",
    ")\n",
    "\n",
    "len(set(clustering_info['clusters_1_level'])), len(set(clustering_info['global_numbering_clusters_2_level']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 44s, sys: 112 ms, total: 1min 44s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%time text_corp, vectorizer = create_text_corp(posts.text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_kw = get_keywords_for_hierarchy(clustering_info, text_corp, feature_names=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_labels, clust_labels2 = convert_keywords_to_cluster_names(res_kw, clustering_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_df = posts[['title', 'pageUrl', 'baseScore', 'commentCount']].reset_index(drop=True).copy()\n",
    "\n",
    "date = pd.to_datetime(posts['postedAt']).dt\n",
    "art_df['date'] = date.date.values\n",
    "art_df['year'] = date.year.values\n",
    "\n",
    "tag_string = posts['tags'].map(lambda x: \"*\" + \"; \".join(x[:5]) + \"*\")\n",
    "art_df['text'] = tag_string + \"\\n\\n\" + posts['body'].map(lambda x: ' ' .join(x.split(' ')[:150]) + '...')\n",
    "art_df['url'] = posts.pageUrl.values\n",
    "\n",
    "art_df['log_score'] = np.log10(np.abs(art_df.baseScore) + 1) * np.sign(art_df.baseScore)\n",
    "art_df['log_n_comments'] = np.log10(art_df.commentCount + 1)\n",
    "\n",
    "art_df['clust1'] = clust_labels\n",
    "art_df['clust2'] = clust_labels2\n",
    "\n",
    "res_arch = dict(\n",
    "    keyword_info=res_kw,\n",
    "    embedding=par_embedding,\n",
    "    art_df=art_df,\n",
    "    clusters_columns=['clust1', 'clust2', 'year', 'log_score', 'log_n_comments'],\n",
    "    metadata_columns=['title', 'baseScore', 'commentCount'],\n",
    "    scatter_params=dict(annotation_col='clust1', ms=3.5),\n",
    "    metadata=None,\n",
    ")\n",
    "\n",
    "pd.to_pickle(res_arch, datap(\"sbert_emb_data.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_artifacts.Artifact at 0x7f19c8c1c100>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art = wandb.Artifact(\"sbert_emb_data\", type=\"dataset\", metadata={'model_name': model_name})\n",
    "art.add_file(datap(\"sbert_emb_data.pkl\"))\n",
    "run.log_artifact(art, aliases=[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ruby-flower-31</strong>: <a href=\"https://wandb.ai/vpetukhov/ea-forum-analysis/runs/3hq1e2l7\" target=\"_blank\">https://wandb.ai/vpetukhov/ea-forum-analysis/runs/3hq1e2l7</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/notebooks/wandb/run-20221109_103443-3hq1e2l7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "94600d5031569c7617ef443af57f47df7391674c50ebfb7f636fa8887522be49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
