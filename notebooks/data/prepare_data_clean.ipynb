{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.dirname(sys.path[0])))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import umap\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import seaborn as sns\n",
    "\n",
    "from src.mnn_umap import prepare_umap_graph, full_umap\n",
    "from src.parsing import read_post_data, get_html_parser\n",
    "from src.paths import get_project_root, abs_path\n",
    "\n",
    "sys.path.append(abs_path(\"TextClusterVisualization/scripts\"))\n",
    "\n",
    "from graph_clustering import get_igraph_from_umap_graph, two_level_clustering, leiden_clustering\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# %env WANDB_NOTEBOOK_NAME=prepare_data_clean\n",
    "import wandb\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvpetukhov\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20221109_091757-2xwcdbyz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/vpetukhov/ea-forum-analysis/runs/2xwcdbyz\" target=\"_blank\">smooth-galaxy-29</a></strong> to <a href=\"https://wandb.ai/vpetukhov/ea-forum-analysis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.login() # relies on WANDB_API_KEY env var\n",
    "run = wandb.init(\n",
    "    project=\"ea-forum-analysis\", job_type=\"processing\", dir=get_project_root()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas:\n",
    "- Timeline with key posts on a topic\n",
    "  - Add time dimension to my search engine?\n",
    "- Convert dendrogram into an actual table of content\n",
    "- Propagate post tags to users, show most active users per dendrogram branch\n",
    "- Improve coloschemes\n",
    "- Add time selection\n",
    "\n",
    "Improving visualization:\n",
    "- Try poincare embeddings\n",
    "- Try sentence transformers instead of word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact posts_encoded:all-mpnet-base-v2, 98.61MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact posts_raw:latest, 272.30MB. 3 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "Done. 0:0:0.0\n"
     ]
    }
   ],
   "source": [
    "# art = run.use_artifact(\"posts_encoded:all-mpnet-base-v2-baseline\")\n",
    "art = run.use_artifact(\"posts_encoded:all-mpnet-base-v2\")\n",
    "art.download()\n",
    "posts_encoded = pd.read_csv(art.file(), index_col=0)\n",
    "posts = Dataset.load_from_disk(run.use_artifact(\"posts_raw:latest\").download()).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10827, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = posts.loc[posts_encoded.index]\n",
    "posts = posts[posts.postedAt.dt.year > 2009]\n",
    "posts_encoded = posts_encoded.loc[posts.index]\n",
    "\n",
    "posts_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts['text'] = posts['title'] + \"\\n\\n\" + posts['body']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_clustering import get_igraph_from_umap_graph, two_level_clustering\n",
    "from preprocessing import normalize_text_doc, create_text_corp\n",
    "from keyword_extraction import get_keywords_for_hierarchy, convert_keywords_to_cluster_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/umap/parametric_umap.py:148: UserWarning: tensorflow_probability not installed or incompatible to current                 tensorflow installation. Setting global_correlation_loss_weight to zero.\n",
      "  warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "from umap.parametric_umap import ParametricUMAP\n",
    "\n",
    "pumap = ParametricUMAP()\n",
    "par_embedding = pumap.fit_transform(posts_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_graph = get_igraph_from_umap_graph(None, graph=umap_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 53)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_info = two_level_clustering(\n",
    "    i_graph, posts_encoded.values, \n",
    "    top_level_resolution=0.0005, second_level_resolution=0.003, \n",
    "    min_size_level1=10, min_size_level2=10\n",
    ")\n",
    "\n",
    "len(set(clustering_info['clusters_1_level'])), len(set(clustering_info['global_numbering_clusters_2_level']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582c6d4cb4b34c8398758a5cf805edc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10763 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "documents_norm = posts.text.progress_map(normalize_text_doc).values\n",
    "documents = [' '.join(doc) for doc in documents_norm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [' '.join(doc) for doc in documents_norm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.keyword_extraction import get_top_keywords_for_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "kws = get_top_keywords_for_cluster(\n",
    "    # text_corp, clustering_info['clusters_1_level'], vectorizer.get_feature_names_out(), n_terms=5, tag_types=None\n",
    "    text_corp, clustering_info['global_numbering_clusters_2_level'], vectorizer.get_feature_names_out(), n_terms=5, tag_types=None\n",
    ")\n",
    "\n",
    "# kws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# text_corp, vectorizer = create_text_corp(documents)\n",
    "res_kw = get_keywords_for_hierarchy(clustering_info, text_corp, feature_names=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_labels, clust_labels2 = convert_keywords_to_cluster_names(res_kw, clustering_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>htmlBody</th>\n",
       "      <th>pageUrl</th>\n",
       "      <th>postedAt</th>\n",
       "      <th>baseScore</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>meta</th>\n",
       "      <th>question</th>\n",
       "      <th>url</th>\n",
       "      <th>tags</th>\n",
       "      <th>user</th>\n",
       "      <th>coauthors</th>\n",
       "      <th>userId</th>\n",
       "      <th>body</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2258qMLTjTu4L77Fu</th>\n",
       "      <td>Can you suggest guidelines for setting / renew...</td>\n",
       "      <td>&lt;p&gt;Hi EA community,&lt;/p&gt;&lt;p&gt;This is my first pos...</td>\n",
       "      <td>https://forum.effectivealtruism.org/posts/2258...</td>\n",
       "      <td>2020-05-14 18:24:32.423000+00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Career choice]</td>\n",
       "      <td>Barth</td>\n",
       "      <td>[]</td>\n",
       "      <td>2fpSGdf4ofpkhvKjt</td>\n",
       "      <td>Hi EA community,\\n\\nThis is my first post here...</td>\n",
       "      <td>Can you suggest guidelines for setting / renew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225Aq4P4jFPoWBrb5</th>\n",
       "      <td>Cause prioritization for downside-focused valu...</td>\n",
       "      <td>&lt;p&gt;&lt;em&gt;Last updated: July 8th 2021. &lt;/em&gt; &lt;/p&gt;...</td>\n",
       "      <td>https://forum.effectivealtruism.org/posts/225A...</td>\n",
       "      <td>2018-01-31 14:47:11.961000+00:00</td>\n",
       "      <td>72</td>\n",
       "      <td>51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Cause prioritization, Philosophy of effective...</td>\n",
       "      <td>Lukas_Gloor</td>\n",
       "      <td>[]</td>\n",
       "      <td>2tRAtc3DtRKjL8hsS</td>\n",
       "      <td>Last updated: July 8th 2021. \\n\\nThis post out...</td>\n",
       "      <td>Cause prioritization for downside-focused valu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               title  \\\n",
       "2258qMLTjTu4L77Fu  Can you suggest guidelines for setting / renew...   \n",
       "225Aq4P4jFPoWBrb5  Cause prioritization for downside-focused valu...   \n",
       "\n",
       "                                                            htmlBody  \\\n",
       "2258qMLTjTu4L77Fu  <p>Hi EA community,</p><p>This is my first pos...   \n",
       "225Aq4P4jFPoWBrb5  <p><em>Last updated: July 8th 2021. </em> </p>...   \n",
       "\n",
       "                                                             pageUrl  \\\n",
       "2258qMLTjTu4L77Fu  https://forum.effectivealtruism.org/posts/2258...   \n",
       "225Aq4P4jFPoWBrb5  https://forum.effectivealtruism.org/posts/225A...   \n",
       "\n",
       "                                          postedAt  baseScore  voteCount  \\\n",
       "2258qMLTjTu4L77Fu 2020-05-14 18:24:32.423000+00:00         10          4   \n",
       "225Aq4P4jFPoWBrb5 2018-01-31 14:47:11.961000+00:00         72         51   \n",
       "\n",
       "                   commentCount   meta  question  url  \\\n",
       "2258qMLTjTu4L77Fu           NaN  False      True  NaN   \n",
       "225Aq4P4jFPoWBrb5          10.0  False     False  NaN   \n",
       "\n",
       "                                                                tags  \\\n",
       "2258qMLTjTu4L77Fu                                    [Career choice]   \n",
       "225Aq4P4jFPoWBrb5  [Cause prioritization, Philosophy of effective...   \n",
       "\n",
       "                          user coauthors             userId  \\\n",
       "2258qMLTjTu4L77Fu        Barth        []  2fpSGdf4ofpkhvKjt   \n",
       "225Aq4P4jFPoWBrb5  Lukas_Gloor        []  2tRAtc3DtRKjL8hsS   \n",
       "\n",
       "                                                                body  \\\n",
       "2258qMLTjTu4L77Fu  Hi EA community,\\n\\nThis is my first post here...   \n",
       "225Aq4P4jFPoWBrb5  Last updated: July 8th 2021. \\n\\nThis post out...   \n",
       "\n",
       "                                                                text  \n",
       "2258qMLTjTu4L77Fu  Can you suggest guidelines for setting / renew...  \n",
       "225Aq4P4jFPoWBrb5  Cause prioritization for downside-focused valu...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_df = posts[['title', 'pageUrl', 'baseScore', 'commentCount']].reset_index(drop=True).copy()\n",
    "\n",
    "date = pd.to_datetime(posts['postedAt']).dt\n",
    "art_df['date'] = date.date.values\n",
    "art_df['year'] = date.year.values\n",
    "\n",
    "art_df['text'] = posts['body'].map(lambda x: ' ' .join(x.split(' ')[:150]) + '...')\n",
    "art_df['url'] = posts.pageUrl.values\n",
    "\n",
    "# art_df['text'] = art_df.abstract.values\n",
    "art_df['log_score'] = np.log10(np.abs(art_df.baseScore) + 1) * np.sign(art_df.baseScore)\n",
    "art_df['log_n_comments'] = np.log10(art_df.commentCount + 1)\n",
    "\n",
    "art_df['clust1'] = clust_labels\n",
    "art_df['clust2'] = clust_labels2\n",
    "\n",
    "res_arch = dict(\n",
    "    keyword_info=res_kw,\n",
    "    embedding=mnn_emb,\n",
    "    art_df=art_df,\n",
    "    clusters_columns=['clust1', 'clust2', 'year', 'log_score', 'log_n_comments'],\n",
    "    metadata_columns=['title', 'baseScore', 'commentCount'],\n",
    "    scatter_params=dict(annotation_col='clust1', ms=3.5),\n",
    "    metadata=None,\n",
    ")\n",
    "\n",
    "pd.to_pickle(res_arch, \"./cache/sbert_emb_data.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94600d5031569c7617ef443af57f47df7391674c50ebfb7f636fa8887522be49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
